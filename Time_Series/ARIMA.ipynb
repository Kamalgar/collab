{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IsSel1vq3rN"
      },
      "source": [
        "# Time Series and Forecasting Models: ARIMA\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "A time series is basically a series of data points ordered in time and is an important factor in predicting stock market trends. In time series forecasting models, time is the independent variable and the goal is to predict future values based on previously observed values.\n",
        "\n",
        "There are many ways to model a time series in order to make predictions including Moving Averages MA(q), Autoregression AR(p), and combining these to create ARMA(p,q), ARIMA(p,q,d), SARIMA(p,q,d)(P,Q,D,s) models.\n",
        "\n",
        "Here we will focus on the AutoRegressive Integrated Moving Average (ARIMA) model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8LfI_oMeV7E"
      },
      "source": [
        "## 2. Install/import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yeKvwbwybmCv",
        "outputId": "31782595-dca1-410a-8008-c45e39dbe04f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.10b0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mplfinance) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from mplfinance) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->mplfinance) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->mplfinance) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.17.0)\n",
            "Downloading mplfinance-0.12.10b0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.10b0\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.4.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.14.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (0.14.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.3.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (75.2.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n",
            "Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pmdarima\n",
            "Successfully installed pmdarima-2.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mplfinance\n",
        "!pip install pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R0YbiLIpfqc0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import zscore\n",
        "\n",
        "#from pmdarima.arima.utils import ndiffs\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.tsa.api as smt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.stattools import coint\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "from itertools import product\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import datetime\n",
        "from datetime import date, timedelta\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpC3P_HTeeAg"
      },
      "source": [
        "## 3. Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvRiP01SejAw"
      },
      "outputs": [],
      "source": [
        "ftse100_stocks = pd.read_pickle(\"ftse100_stocks.pkl\")\n",
        "\n",
        "ftse100_stocks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTYPzHcjgS5x"
      },
      "outputs": [],
      "source": [
        "# Create dataframe of AZN.L stock data\n",
        "\n",
        "azn =  ftse100_stocks['AZN.L']\n",
        "\n",
        "azn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTGrNTeYfkt-"
      },
      "outputs": [],
      "source": [
        "# Create Dataframe for Adjusted Close prices\n",
        "\n",
        "azn_adj = azn[['Adj Close']].copy()\n",
        "azn_adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLr8yAz6Sm6l"
      },
      "outputs": [],
      "source": [
        "# Plot Adjusted Close price\n",
        "\n",
        "def azn_adj_plot():\n",
        "  sns.set(rc={'figure.figsize':(16, 8)})\n",
        "  azn_adj.plot(label=f\"{label_txt}\")\n",
        "  plt.title(f\"{title_txt}\", color = 'black', fontsize = 20)\n",
        "  plt.xlabel('Date', color = 'black', fontsize = 15)\n",
        "  plt.ylabel('Stock Price (p)', color = 'black', fontsize = 15);\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhODpfbkSq6d"
      },
      "outputs": [],
      "source": [
        "title_txt = \"AZN.L Adjusted Close Price from 2010-2019\"\n",
        "label_txt = \"AZN.L Adj Close\"\n",
        "\n",
        "azn_adj_plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyib9MfIsVIv"
      },
      "source": [
        "## 4. Seasonality\n",
        "\n",
        "Seasonality in time series data refers to period fluctuations or cyclical patterns. Differencing can be used to check for seasonality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftQ2p79ABvXL"
      },
      "outputs": [],
      "source": [
        "# Plot Adjusted Close price and price after differencing by one year\n",
        "# removing the first year as it's NaN\n",
        "\n",
        "year_diff = azn_adj.diff(periods=365)[365:]\n",
        "plt.figure(figsize=(17, 8))\n",
        "plt.plot(year_diff .index, year_diff , label='Year differenced')\n",
        "plt.plot(azn.index, azn['Adj Close'], label='Standard')\n",
        "plt.title(\"Differencing to check for seasonality\", color = 'black', fontsize = 20)\n",
        "plt.xlabel('Year', color = 'black', fontsize = 15)\n",
        "plt.ylabel('Stock Price (p)', color = 'black', fontsize = 15)\n",
        "plt.grid(True)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgY1fyQ2pbh"
      },
      "source": [
        "The difference transform does not appear to show a less volatile time series so a strong seasonal trend is unlikely. Seasonality can also be derived from an autocorrelation plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNc5URTP55Gy"
      },
      "source": [
        "## 5. Stationarity\n",
        "\n",
        "A time series is said to be stationary if its statistical properties do not change over time. In other words, it has constant mean and variance, and covariance is independent of time. Stock prices are often non-stationary and may contain trends or volatility but different transformations can be made to turn the time series into a stationary process so that it can be modelled.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3YtG8KfsZeM"
      },
      "source": [
        "### 5.1 Augmented Dickey-Fuller (ADF) test\n",
        "\n",
        "Augmented Dickey-Fuller is the statistical test that we run to determine if a time series is stationary or not. It tests the null hypothesis ($H_{0}$) that a unit root is present in an autoregressive model. If it is, then p > 0, and the null hypothesis that the process is not stationary is true.\n",
        "\n",
        "Otherwise, p = 0, the null hypothesis is rejected, and the process is considered to be stationary. The alternate hypothesis ($H_{1}$) that the data is stationary is accepted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qao4yILpaXR6"
      },
      "outputs": [],
      "source": [
        "# ADF Test to check if price series is stationary\n",
        "\n",
        "result = adfuller(azn_adj.dropna())\n",
        "print(f'ADF Statistic: {result[0]}')\n",
        "print(f'p-value: {result[1]}')\n",
        "for key, value in result[4].items():\n",
        "    print('Critial Values:')\n",
        "    print(f'   {key}, {value}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkp6gAv1tNi"
      },
      "source": [
        "The p-value is greater than the significance level of 0.05 and the ADF statistic is higher than any of the critical values, therefore the series is non-stationary. The next step is to determine the order of differencing required to make the series stationary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HkvGWNyskO_"
      },
      "source": [
        "### 5.2 Autocorrelation Function (ACF)\n",
        "\n",
        "Autocorrelation is the similarity between observations as a function of the time lag between them. The ACF plot, or correlogram, will tell us the order of differencing required to remove any autocorrelation in the series.\n",
        "\n",
        "Autocorrelation is the similarity between observations of the same series at previous times as a function of the time lag between them.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b05epicHhD9V"
      },
      "outputs": [],
      "source": [
        "# Plot stock price and ACF plot\n",
        "\n",
        "def ts_acf(y, lags=None, figsize=(12, 4)):\n",
        "    plt.style.use('seaborn')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    layout = (1,2)\n",
        "    ts_ax = plt.subplot2grid(layout, (0,0))\n",
        "    acf_ax = plt.subplot2grid(layout, (0,1))\n",
        "\n",
        "    y.plot(ax=ts_ax)\n",
        "    ts_ax.set_title('AZN.L Adjusted Close Price')\n",
        "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
        "    plt.tight_layout()\n",
        "\n",
        "ts_acf(azn_adj, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzttQegMpAuU"
      },
      "source": [
        "The above plots show the original price series and the autocorrelation. There is high autocorrelation, and no clear seasonality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng95HPY7yW26"
      },
      "source": [
        "## 6. Differencing (d)\n",
        "\n",
        "The purpose of differencing it to make the time series stationary. The parameter **d** is the order of differencing required to achieve this.  In stationary time series d would be 0 but we need to find the order appropriate to our time series.\n",
        "\n",
        "It is the order of Integration (the (I)ntegrated In ARIMA)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL7uEQ6MtG6V"
      },
      "source": [
        "### 6.1 Difference once\n",
        "\n",
        "To get rid of the high autocorrelation and to make the process stationary, we will take the first difference and subtract the time series from itself with a lag of one day (previous value from the current value) to get the returns of the Adjusted Close price.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD7bhVNxrXaN"
      },
      "outputs": [],
      "source": [
        "# Calculate the first differences of the series by comparing with the element in the previous row\n",
        "# and drop NaNs\n",
        "\n",
        "diff1 = azn_adj.diff().dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q1ghl2isKMf"
      },
      "outputs": [],
      "source": [
        "# Plot first order of differencing and ACF plot\n",
        "\n",
        "def diff1_plot(y, lags=None, figsize=(12, 4)):\n",
        "    plt.style.use('seaborn')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    layout = (1,2)\n",
        "    ax1 = plt.subplot2grid(layout, (0,0))\n",
        "    acf_ax = plt.subplot2grid(layout, (0,1))\n",
        "\n",
        "    y.plot(ax=ax1)\n",
        "    ax1.set_title('Difference once')\n",
        "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
        "    plt.tight_layout()\n",
        "\n",
        "diff1_plot(diff1, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNqKr3T-yoIT"
      },
      "source": [
        "We can see that the returns randomly distribute around the mean of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-8ral31uC7"
      },
      "source": [
        "### 6.2 Difference twice\n",
        "\n",
        "Differencing once might not be enough to make the series stationary which may require multiple orders of differencing. We will difference twice, or take the returns of the returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1rDoYBB1YCq"
      },
      "outputs": [],
      "source": [
        "# Calculate the second order of differencing and drop NaNs\n",
        "\n",
        "diff2 = azn_adj.diff().diff().dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s2zpUe52-F4"
      },
      "outputs": [],
      "source": [
        "# Plot second order of differencing and ACF plot\n",
        "\n",
        "def diff2_plot(y, lags=None, figsize=(12, 4)):\n",
        "    plt.style.use('seaborn')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    layout = (1,2)\n",
        "    ax1 = plt.subplot2grid(layout, (0,0))\n",
        "    acf_ax = plt.subplot2grid(layout, (0,1))\n",
        "\n",
        "    y.plot(ax=ax1)\n",
        "    ax1.set_title('Difference twice')\n",
        "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
        "    plt.tight_layout()\n",
        "\n",
        "diff2_plot(diff2, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVUE6LA23ZQN"
      },
      "source": [
        "The lag in second order of differencing goes into the far negative which indicates it might have been overdifferenced, so we will choose the order of differencing as 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJO2LTzvMaKr"
      },
      "source": [
        "We can also use ndiffs in the **pmdarima** package to get the order of differencing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRW0njjs3l7U"
      },
      "outputs": [],
      "source": [
        "ndiffs(azn_adj, test=\"adf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohVFNdTQwStW"
      },
      "source": [
        "The differencing required to make the time series stationary is 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clZ4qC7MykOf"
      },
      "source": [
        "## 7. Auto Regressive (AR) term (p)\n",
        "\n",
        "Auto regression is a regression of the time series with itself. We try to find out how correlated the current value is to its previous values with some lag. The parameter **p** represents the maximum lag which is found by looking at the Partial Autocorrelation plot to identify the lag after which most lags are not significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dmAOPTezUFV"
      },
      "source": [
        "### 7.1 Partial Autocorrelation Function (PACF)\n",
        "\n",
        "The PACF plot is useful for determining the order of an AR(p) process. It only describes the direct relationship between an observation and its lag. This would suggest that there would be no correlation for lag values beyond the maximum lag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ9XQRDxcbbY"
      },
      "outputs": [],
      "source": [
        "# Plot first order of differencing and PACF plot\n",
        "\n",
        "def pacf_plot(y, lags=None, figsize=(12, 4)):\n",
        "    plt.style.use('seaborn')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    layout = (1,2)\n",
        "    ax1 = plt.subplot2grid(layout, (0,0))\n",
        "    pacf_ax = plt.subplot2grid(layout, (0,1))\n",
        "\n",
        "    y.plot(ax=ax1)\n",
        "    ax1.set_title('Difference once')\n",
        "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
        "    plt.tight_layout()\n",
        "\n",
        "pacf_plot(diff1, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mirhYXEk0OjJ"
      },
      "source": [
        "The PACF lag of 3 is above the significance line after which the PACF coefficients are not significant anymore. Therefore,\n",
        "we will assume an autoregressive process of order 3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH7nxMwd0gNi"
      },
      "source": [
        "## 8. Moving Average (MA) term (q)\n",
        "\n",
        "\n",
        "The Moving Average term, represented by the parameter **q**, refers to the number of lagged forecast errors used to predict future values. It is used to reduce noise in a model or smooth it out. The longer the moving average period, the more smoothed out the noise would be.\n",
        "\n",
        "An ACF plot is used to identify the correct q value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3liMONk00w9"
      },
      "source": [
        "### 8.1 Autocorrelation function (ACF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afyaXFK_a8up"
      },
      "outputs": [],
      "source": [
        "# Plot ACF to find q term for number of lagged forecast errors\n",
        "\n",
        "def diff1_plot(y, lags=None, figsize=(12, 4)):\n",
        "    plt.style.use('seaborn')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    layout = (1,2)\n",
        "    ax1 = plt.subplot2grid(layout, (0,0))\n",
        "    acf_ax = plt.subplot2grid(layout, (0,1))\n",
        "\n",
        "    y.plot(ax=ax1)\n",
        "    ax1.set_title('Difference once')\n",
        "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
        "    plt.tight_layout()\n",
        "\n",
        "diff1_plot(diff1, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAGSJWLmFVGr"
      },
      "source": [
        "The ACF plot forecast error 3 is above the significance line and represents the biggest lag after which other lags are not significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVSAkgv4u8XF"
      },
      "source": [
        "## 9. Run ADF test on differenced time series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH5f7sGRuj6G"
      },
      "outputs": [],
      "source": [
        "# ADF test to check if price series is now stationary\n",
        "\n",
        "result2 = adfuller(diff1)\n",
        "print(f'ADF Statistic: {result2[0]}')\n",
        "print(f'p-value: {result2[1]}')\n",
        "for key, value in result2[4].items():\n",
        "    print('Critial Values:')\n",
        "    print(f'   {key}, {value}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITIHLUj3vIS4"
      },
      "source": [
        "The p-value is 0, less than the significance level of 0.05 and the ADF statistic is lower than all of the critical values. The null hypothesis is rejected, and the process is considered to be stationary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8El7gM1LF8nB"
      },
      "source": [
        "## 10. Modelling\n",
        "\n",
        "### 10.1 Fitting the ARIMA model\n",
        "\n",
        "We will now fit the ARIMA model with the (p, d, q) terms of order (3, 1, 3) observed manually from differencing, ACF and PACF plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZe19HzvgGHg"
      },
      "outputs": [],
      "source": [
        "# Fit ARIMA model with (p, d, q) terms\n",
        "\n",
        "model = ARIMA(azn_adj, order=(3, 1, 3))\n",
        "result = model.fit(disp=0)\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soXxlN67z2kw"
      },
      "source": [
        "We can see from the results summary that there are three AR terms and three MA terms, which are the coefficents for the linear regression, and the p-value for each of them. If any of the coefficients were very close to zero, and the p-value very high, we could remove that term. The p-value needs to be low for the terms to be important for our regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebyu6rxCsjo_"
      },
      "source": [
        "### Plot Residual errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr7jKFwDg6Ao"
      },
      "outputs": [],
      "source": [
        "residuals = pd.DataFrame(result.resid)\n",
        "residuals.plot();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_e2pqoOs9h"
      },
      "source": [
        "The residuals are distributed around the mean of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb0H2t_9J1D1"
      },
      "source": [
        "### 10.2 Grid search to select the best order for ARIMA model\n",
        "\n",
        "In order to optimise our model, for each combination of parameters we fit an ARIMA model with the SARIMAX() function and assess its overall performance. This will result in a dataframe listing the orders and corresponding Akaike’s Information Criterion (AIC) with best models in descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmJZ5_GG-yx9"
      },
      "outputs": [],
      "source": [
        "def optimise_ARIMA(order_list, exog):\n",
        "    \"\"\"\n",
        "    Optimise ARIMA model\n",
        "\n",
        "    :param order_list: list with (p, d, q) tuples\n",
        "    :param exog: the exogenous variable\n",
        "\n",
        "    :return: dataframe with parameters and corresponding AIC\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for order in tqdm(order_list):\n",
        "        try:\n",
        "            model = SARIMAX(exog, order=order).fit(disp=0)\n",
        "        except:\n",
        "            continue\n",
        "        aic = model.aic\n",
        "        results.append([order, model.aic])\n",
        "\n",
        "    result_df = pd.DataFrame(results)\n",
        "    result_df.columns = ['(p, d, q)', 'AIC']\n",
        "    #Sort in ascending order, lower AIC is better\n",
        "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
        "\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WpQVQHKcTlY"
      },
      "source": [
        "### 10.3 Parameters to iterate through"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88rkxf0D-_XN"
      },
      "outputs": [],
      "source": [
        "# Parameters to iterate through\n",
        "ps = range(0, 8, 1)\n",
        "d = 1\n",
        "qs = range(0, 8, 1)\n",
        "\n",
        "# Create a list with all possible combination of parameters\n",
        "parameters = product(ps, qs)\n",
        "parameters_list = list(parameters)\n",
        "\n",
        "order_list = []\n",
        "\n",
        "for each in parameters_list:\n",
        "    each = list(each)\n",
        "    each.insert(1, 1)\n",
        "    each = tuple(each)\n",
        "    order_list.append(each)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zpTsHFQck0x"
      },
      "source": [
        "### 10.4 Search for optimum parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrfyyKpM_Hqb"
      },
      "outputs": [],
      "source": [
        "result_df = optimise_ARIMA(order_list, exog=azn_adj['Adj Close'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhBSY0VsA9t-"
      },
      "outputs": [],
      "source": [
        "# Print dataframe of results\n",
        "\n",
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_TFi0UOKzXi"
      },
      "source": [
        "The order associated with the lowest AIC is (4,1,4). Therefore, this suggests an ARIMA model with an AR(4) process and an MA(4) process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "offZwaOBLcDl"
      },
      "source": [
        "### 10.5 Fitting the best ARIMA model after Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XWAEtUnRtzf"
      },
      "outputs": [],
      "source": [
        "# Fit and print a summary of the best model, which is ARIMA (4,1,4)\n",
        "\n",
        "best_model = ARIMA(azn_adj, order=(4, 1, 4)).fit(disp=0)\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUVKX-zPF0_"
      },
      "source": [
        "## 11. Study the residuals\n",
        "\n",
        "Ideally, the residuals will be white noise, with no autocorrelation. One way to test this is by running the **Ljung-Box test** that checks if autocorrelation exists in a time series. The null hypothesis is that the residuals from the ARIMA model have no autocorrelation (or in simple terms - the model is just fine).\n",
        "\n",
        "We would like to fail to reject the null hypothesis and see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpkhO6KfTcze"
      },
      "outputs": [],
      "source": [
        "# Ljung-Box test and Augmented Dickey-Fuller test\n",
        "ljung_box, p_value = acorr_ljungbox(best_model.resid)\n",
        "\n",
        "print(f'Ljung-Box test: {ljung_box[:10]}')\n",
        "print(f'p-value: {p_value[:10]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG4oiy79Gr97"
      },
      "source": [
        "Looking at the p-values above, we can see that they are above 0.05. Therefore, we\n",
        "cannot reject the null hypothesis, and the residuals are indeed not correlated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7UlovZBYG_q"
      },
      "source": [
        "### 11.1 Confirm with PACF and ACF plots of residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKmM5C6QHhz7"
      },
      "outputs": [],
      "source": [
        "# Plot PACF and ACF\n",
        "\n",
        "def pacf_acf_plot(y, lags=None, figsize=(12, 4)):\n",
        "    plt.style.use('seaborn')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    layout = (1,2)\n",
        "    pacf_ax = plt.subplot2grid(layout, (0,0))\n",
        "    acf_ax = plt.subplot2grid(layout, (0,1))\n",
        "\n",
        "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
        "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
        "    plt.tight_layout()\n",
        "\n",
        "pacf_acf_plot(best_model.resid, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDHc4nyzJOEP"
      },
      "source": [
        "The plots above resemble those of white noise, therefore this model is ready to be used for forecasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6BBTcCGZ_NH"
      },
      "source": [
        "## 12. Predictions\n",
        "\n",
        "### Plot actual vs predicted result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPE6uDShGqL1"
      },
      "outputs": [],
      "source": [
        "# Plot Actual vs predicted price for last 6 months of 2019\n",
        "\n",
        "plt.rc(\"figure\", figsize=(16,8))\n",
        "\n",
        "best_model.plot_predict(\n",
        "      start=2391,\n",
        "      end=2517,\n",
        "      dynamic=False,\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtRjmHNfaNQF"
      },
      "source": [
        "Our predictions are very close to our actual values so our ARIMA model is fitted correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYpP4u1ceft0"
      },
      "source": [
        "### Plot the predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJQe8tpiGucW"
      },
      "outputs": [],
      "source": [
        "# Plot Actual vs predicted price extending 2 months into 2020\n",
        "\n",
        "plt.rc(\"figure\", figsize=(16,8))\n",
        "best_model.plot_predict(\n",
        "      start=2400,\n",
        "      end=2559,\n",
        "      dynamic=False,\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OnJISpLhGxn"
      },
      "source": [
        "We can forecast the next 60 days and visualise the data points for Adjusted Close prices."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ARIMA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}